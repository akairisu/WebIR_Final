{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BOOKS_DESCRIPTIONS = \"./data/descriptions\"\n",
    "PATH_BOOKS_IF_CSV = \"./data/IF_CSV\"\n",
    "PATH_CORPUS = \"./data/corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(PATH_BOOKS_IF_CSV)\n",
    "corpus_IF = pd.read_csv(f'{PATH_CORPUS}/corpus_IF.csv', names=['word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, d_IF, query, corpus_IF):\n",
    "        self._d_IF = d_IF\n",
    "        self._query = query.split()\n",
    "        self._corpus_IF = corpus_IF\n",
    "        self._lambda = 0.5\n",
    "    \n",
    "    def get_term_probability(self, term, d):\n",
    "        Ld = len(d)\n",
    "        tf = d.loc[d['word'] == term, 'count']\n",
    "        if len(tf) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            tf = tf.iloc[0]\n",
    "        \n",
    "        return tf/Ld\n",
    "    \n",
    "    def get_doc_probability(self):\n",
    "        Pdq = 1\n",
    "        for t in self._query:\n",
    "            PMd = self.get_term_probability(t, self._d_IF)\n",
    "            PMc = self.get_term_probability(t, self._corpus_IF)\n",
    "            \n",
    "            Pdq *= (1-self._lambda)*PMc + self._lambda*PMd\n",
    "        \n",
    "        return Pdq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevanceFeedback:\n",
    "    def __init__(self, original_query, documents, corpus_IF):\n",
    "        self._original_query = original_query.split()\n",
    "        self._modified_query = ''\n",
    "        self._documents = documents\n",
    "        self._corpus_IF = corpus_IF\n",
    "        self._N = 10000\n",
    "    \n",
    "    def get_idf(self, term):\n",
    "        df = pd.read_csv(f'{PATH_CORPUS}/df.csv', names=['word', 'count'])\n",
    "        try:\n",
    "            idf = np.log(self._N / df.loc[df['word'] == term, 'count'].iloc[0])\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "        return idf\n",
    "    \n",
    "    def get_doc_relevant_words(self, d, max_words=1):\n",
    "        tf_idf = {}\n",
    "        d_IF = pd.read_csv(f'{PATH_BOOKS_IF_CSV}/{d}.csv', names=['word', 'count'])\n",
    "        \n",
    "        for index, row in d_IF.iterrows():\n",
    "            c_term = row['word']\n",
    "            c_tf = int(row['count'])\n",
    "            tf_idf[c_term] = c_tf * self.get_idf(c_term)\n",
    "        tf_idf = {k: v for k, v in sorted(tf_idf.items(), key=lambda item: item[1], reverse=True)}\n",
    "        rel_words = list(tf_idf)[:max_words]\n",
    "        \n",
    "        return rel_words\n",
    "    \n",
    "    def get_feedback_words(self):\n",
    "        fb_words = []\n",
    "        print(self._documents)\n",
    "        for d in self._documents:\n",
    "            fb_words.append(self.get_doc_relevant_words(d))\n",
    "        \n",
    "        return [item for sublist in fb_words for item in sublist]\n",
    "    \n",
    "    def create_modified_query(self):\n",
    "        fb_words = self.get_feedback_words()\n",
    "        self._modified_query = list(set(self._original_query).union(set(fb_words)))\n",
    "        \n",
    "        return self._modified_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookSearch:\n",
    "    def __init__(self, query, corpus_IF):\n",
    "        self._query = query\n",
    "        self._book_rankings = {}\n",
    "        \n",
    "    def execute_query(self, query, max_docs=10):\n",
    "        ranking = {}\n",
    "        for index, file in enumerate(files):\n",
    "            d_IF = pd.read_csv(f'{PATH_BOOKS_IF_CSV}/{file}', names=['word', 'count'])\n",
    "            lm = LanguageModel(d_IF, query, corpus_IF)\n",
    "            clean_name = file.replace('.csv', '')\n",
    "            ranking[clean_name] = lm.get_doc_probability()\n",
    "            del lm\n",
    "        sorted_rankings = {k: v for k, v in sorted(ranking.items(), key=lambda item: item[1], reverse=True)}\n",
    "        culled_rankings = list(sorted_rankings)[:max_docs]\n",
    "        \n",
    "        return culled_rankings\n",
    "    \n",
    "    def execute_relevance_feedback(self, query, rankings, docs_used=3):\n",
    "        rf = RelevanceFeedback(query, rankings[:docs_used], corpus_IF)\n",
    "        mod_query = rf.create_modified_query()\n",
    "        mod_query_string = ' '.join(mod_query)\n",
    "                               \n",
    "        return mod_query_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'fantasy adventure'\n",
    "bs = BookSearch(query, corpus_IF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rf = bs.execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['45', '4468', '7195', '8817', '8617', '6284', '2285', '2399', '8373', '5923']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['45', '4468', '7195']\n"
     ]
    }
   ],
   "source": [
    "mod_query = bs.execute_relevance_feedback(query, no_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pi fantasy Haroun Charlie adventure'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BookSearch(mod_query, corpus_IF)\n",
    "with_rf = bs.execute_query(mod_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_rf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
